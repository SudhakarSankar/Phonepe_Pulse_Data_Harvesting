{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This file (phonepetest2) is used to collect all the data and store in SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os    # local file select\n",
    "import json\n",
    "import pandas as pd\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggre_Insurance\n",
    "\n",
    "path1 = \"C:/Sudhakar/Projects/Phonepe Pulse Data/Dataset & Documents/pulse/data/aggregated/insurance/country/india/state/\"\n",
    "columns1 = {\"States\":[], \"Years\":[], \"Quarters\":[], \"Transaction_type\":[], \"Transaction_count\":[],\"Transaction_amount\":[]}\n",
    "\n",
    "\n",
    "agg_insurance_state_list = os.listdir(path1)\n",
    "for state in agg_insurance_state_list:\n",
    "    current_state = path1 + state + \"/\" \n",
    "    #print(current_state)\n",
    "    \n",
    "    agg_insurance_year_list =  os.listdir(current_state)\n",
    "    for year in agg_insurance_year_list:\n",
    "        current_year = current_state + year + \"/\"\n",
    "        #print(current_year)\n",
    "        \n",
    "        agg_insurance_json_file_list = os.listdir(current_year)\n",
    "        #print(agg_tra_json_file_list)\n",
    "        for json_file in agg_insurance_json_file_list:\n",
    "            current_json_file = current_year + json_file\n",
    "            \n",
    "            json_file_data = open(current_json_file, \"r\")  \n",
    "            json_File_values = json.load(json_file_data)\n",
    "            \n",
    "            for json_file_value_get in json_File_values[\"data\"][\"transactionData\"]:\n",
    "                #print(json_file_value_get)\n",
    "                name = json_file_value_get[\"name\"]\n",
    "                #print(name)\n",
    "                count = json_file_value_get[\"paymentInstruments\"][0][\"count\"]\n",
    "                amount = json_file_value_get[\"paymentInstruments\"][0][\"amount\"]\n",
    "    \n",
    "                columns1[\"Transaction_type\"].append(name)\n",
    "                columns1[\"Transaction_count\"].append(count)\n",
    "                columns1[\"Transaction_amount\"].append(amount)\n",
    "    \n",
    "                columns1[\"States\"].append(state)\n",
    "                columns1[\"Years\"].append(year)\n",
    "                columns1[\"Quarters\"].append(int(json_file.strip(\".json\")))\n",
    "                \n",
    "aggre_insurance = pd.DataFrame(columns1)\n",
    "\n",
    "aggre_insurance['States']=aggre_insurance['States'].str.title()\n",
    "aggre_insurance['States']=aggre_insurance['States'].str.replace('-',' ')\n",
    "aggre_insurance['States']=aggre_insurance['States'].str.replace('Dadra & Nagar Haveli & Daman & Diu' , 'Dadra and Nagar Haveli and Daman and Diu')\n",
    "aggre_insurance['States']=aggre_insurance['States'].str.replace('Andaman & Nicobar Islands','Andaman & Nicobar')\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggre_insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggre_transaction\n",
    "\n",
    "path2 = \"C:/Sudhakar/Projects/Phonepe Pulse Data/Dataset & Documents/pulse/data/aggregated/transaction/country/india/state/\"\n",
    "columns2 = {\"States\":[], \"Years\":[], \"Quarters\":[], \"Transaction_type\":[], \"Transaction_count\":[],\"Transaction_amount\":[]}\n",
    "\n",
    "agg_tra_state_list = os.listdir(path2)\n",
    "for state in agg_tra_state_list:\n",
    "    current_state = path2 + state + \"/\" \n",
    "    #print(current_state)\n",
    "    \n",
    "    agg_tra_year_list =  os.listdir(current_state)\n",
    "    #print(agg_tra_year_list)\n",
    "    for year in agg_tra_year_list:\n",
    "        current_year = current_state + year + \"/\"\n",
    "        #print(current_year)\n",
    "        \n",
    "        agg_tra_json_file_list = os.listdir(current_year)\n",
    "        # print(agg_tra_json_file_list)\n",
    "        for json_file in agg_tra_json_file_list:\n",
    "            current_json_file = current_year + json_file\n",
    "            \n",
    "            json_file_data = open(current_json_file, \"r\")  \n",
    "            json_File_values = json.load(json_file_data)\n",
    "            \n",
    "            for json_file_value_get in json_File_values[\"data\"][\"transactionData\"]:\n",
    "                #print(json_file_value_get)\n",
    "                name = json_file_value_get[\"name\"]\n",
    "                #print(name)\n",
    "                count = json_file_value_get[\"paymentInstruments\"][0][\"count\"]\n",
    "                amount = json_file_value_get[\"paymentInstruments\"][0][\"amount\"]\n",
    "    \n",
    "                columns2[\"Transaction_type\"].append(name)\n",
    "                columns2[\"Transaction_count\"].append(count)\n",
    "                columns2[\"Transaction_amount\"].append(amount)\n",
    "    \n",
    "                columns2[\"States\"].append(state)\n",
    "                columns2[\"Years\"].append(year)\n",
    "                columns2[\"Quarters\"].append(int(json_file.strip(\".json\")))\n",
    "                \n",
    "aggre_transaction = pd.DataFrame(columns2)\n",
    "\n",
    "aggre_transaction['States']=aggre_transaction['States'].str.title()\n",
    "aggre_transaction['States']=aggre_transaction['States'].str.replace('-',' ')\n",
    "aggre_transaction['States']=aggre_transaction['States'].str.replace('Dadra & Nagar Haveli & Daman & Diu' , 'Dadra and Nagar Haveli and Daman and Diu')\n",
    "aggre_transaction['States']=aggre_transaction['States'].str.replace('Andaman & Nicobar Islands','Andaman & Nicobar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggre_transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggre_ User\n",
    "path3 = \"C:/Sudhakar/Projects/Phonepe Pulse Data/Dataset & Documents/pulse/data/aggregated/user/country/india/state/\"\n",
    "Column3 = {\"States\":[], \"Years\":[], \"Quarters\":[], \"Brands\":[], \"Transaction_count\":[], \"Percentage\":[]}\n",
    "\n",
    "agg_user_state_list = os.listdir(path3)\n",
    "for state in agg_user_state_list:\n",
    "    current_state = path3 + state + \"/\"\n",
    "    # print(current_state)\n",
    "    \n",
    "    agg_user_year_list = os.listdir(current_state)\n",
    "    #print(agg_user_year_list)\n",
    "    for year in agg_user_year_list:\n",
    "        current_year = current_state + year + \"/\"\n",
    "        # print(current_year)\n",
    "        \n",
    "        agg_user_json_file_list  = os.listdir(current_year)\n",
    "        # print(agg_user_json_file_list)\n",
    "        for json_file in agg_user_json_file_list:\n",
    "          current_json_file = current_year + json_file\n",
    "        #   print(current_json_file)\n",
    "\n",
    "          json_file_data = open(current_json_file, \"r\")  \n",
    "          json_File_values = json.load(json_file_data)\n",
    "\n",
    "          try:\n",
    "            for json_file_values_get in json_File_values[\"data\"][\"usersByDevice\"]:\n",
    "            #   print(json_file_values_get)\n",
    "              Brand = json_file_values_get[\"brand\"]\n",
    "              #print(Brand)\n",
    "              Count = json_file_values_get[\"count\"]\n",
    "              Percentage = json_file_values_get[\"percentage\"]\n",
    "              \n",
    "              Column3[\"Brands\"].append(Brand)\n",
    "              Column3[\"Transaction_count\"].append(Count)\n",
    "              Column3[\"Percentage\"].append(Percentage)\n",
    "              Column3[\"States\"].append(state)\n",
    "              Column3[\"Years\"].append(year)\n",
    "              Column3[\"Quarters\"].append(int(json_file.strip(\".json\")))\n",
    "          except:\n",
    "            pass\n",
    "          \n",
    "aggre_user = pd.DataFrame(Column3)\n",
    "\n",
    "aggre_user['States']=aggre_user['States'].str.title()\n",
    "aggre_user['States']=aggre_user['States'].str.replace('-',' ')\n",
    "aggre_user['States']=aggre_user['States'].str.replace('Dadra & Nagar Haveli & Daman & Diu' , 'Dadra and Nagar Haveli and Daman and Diu')\n",
    "aggre_user['States']=aggre_user['States'].str.replace('Andaman & Nicobar Islands','Andaman & Nicobar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggre_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_insurance\n",
    "\n",
    "path4 = \"C:/Sudhakar/Projects/Phonepe Pulse Data/Dataset & Documents/pulse/data/map/insurance/hover/country/india/state/\"\n",
    "column4 = {\"States\":[], \"Years\":[], \"Quarters\":[], \"District\":[], \"Transaction_count\":[], \"Transaction_amount\":[]}\n",
    "\n",
    "map_insurance_state_list = os.listdir(path4)\n",
    "for state in map_insurance_state_list:\n",
    "    current_state = path4 + state + \"/\"\n",
    "    #print(current_state)\n",
    "    \n",
    "    map_insurance_year_list = os.listdir(current_state)\n",
    "    for year in map_insurance_year_list:\n",
    "        current_year = current_state + year + \"/\"\n",
    "        #print(current_year)\n",
    "        \n",
    "        map_insurance_json_file_list = os.listdir(current_year)\n",
    "        for json_file in map_insurance_json_file_list:\n",
    "            current_json_file = current_year + json_file \n",
    "            \n",
    "            json_file_data_3 = open(current_json_file, \"r\")\n",
    "            json_File_values_3 = json.load(json_file_data_3)\n",
    "            #print(json_File_values_3)\n",
    "            \n",
    "            for json_file_value_get_3 in json_File_values_3[\"data\"][\"hoverDataList\"]:\n",
    "                name = json_file_value_get_3[\"name\"]\n",
    "                Count = json_file_value_get_3[\"metric\"][0][\"count\"]\n",
    "                Amount = json_file_value_get_3[\"metric\"][0][\"amount\"]\n",
    "                \n",
    "                column4[\"States\"].append(state) \n",
    "                column4[\"Years\"].append(year) \n",
    "                column4[\"Quarters\"].append(int(json_file.strip(\".json\"))) \n",
    "                column4[\"District\"].append(name)  \n",
    "                column4[\"Transaction_count\"].append(Count)   \n",
    "                column4[\"Transaction_amount\"].append(Amount)\n",
    "                \n",
    "map_insurance = pd.DataFrame(column4)\n",
    "\n",
    "map_insurance['States']=map_insurance['States'].str.title()\n",
    "map_insurance['States']=map_insurance['States'].str.replace('-',' ')\n",
    "map_insurance['States']=map_insurance['States'].str.replace('Dadra & Nagar Haveli & Daman & Diu' , 'Dadra and Nagar Haveli and Daman and Diu')\n",
    "map_insurance['States']=map_insurance['States'].str.replace('Andaman & Nicobar Islands','Andaman & Nicobar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_transaction\n",
    "\n",
    "path5 = \"C:/Sudhakar/Projects/Phonepe Pulse Data/Dataset & Documents/pulse/data/map/transaction/hover/country/india/state/\"\n",
    "column5 = {\"States\":[], \"Years\":[], \"Quarters\":[], \"District\":[], \"Transaction_count\":[], \"Transaction_amount\":[]}\n",
    "\n",
    "map_trans_state_list = os.listdir(path5)\n",
    "for state in map_trans_state_list:\n",
    "    current_state = path5 + state + \"/\"\n",
    "    #print(current_state)\n",
    "    \n",
    "    map_trans_year_list = os.listdir(current_state)\n",
    "    for year in map_trans_year_list:\n",
    "        current_year = current_state + year + \"/\"\n",
    "        #print(current_year)\n",
    "        \n",
    "        map_trans_json_file_list = os.listdir(current_year)\n",
    "        for json_file in map_trans_json_file_list:\n",
    "            current_json_file = current_year + json_file \n",
    "            \n",
    "            json_file_data_3 = open(current_json_file, \"r\")\n",
    "            json_File_values_3 = json.load(json_file_data_3)\n",
    "            #print(json_File_values_3)\n",
    "            \n",
    "            for json_file_value_get_3 in json_File_values_3[\"data\"][\"hoverDataList\"]:\n",
    "                name = json_file_value_get_3[\"name\"]\n",
    "                Count = json_file_value_get_3[\"metric\"][0][\"count\"]\n",
    "                Amount = json_file_value_get_3[\"metric\"][0][\"amount\"]\n",
    "                \n",
    "                column5[\"States\"].append(state) \n",
    "                column5[\"Years\"].append(year) \n",
    "                column5[\"Quarters\"].append(int(json_file.strip(\".json\"))) \n",
    "                column5[\"District\"].append(name)  \n",
    "                column5[\"Transaction_count\"].append(Count)   \n",
    "                column5[\"Transaction_amount\"].append(Amount)\n",
    "\n",
    "map_transaction = pd.DataFrame(column5)\n",
    "\n",
    "map_transaction['States']=map_transaction['States'].str.title()\n",
    "map_transaction['States']=map_transaction['States'].str.replace('-',' ')\n",
    "map_transaction['States']=map_transaction['States'].str.replace('Dadra & Nagar Haveli & Daman & Diu' , 'Dadra and Nagar Haveli and Daman and Diu')\n",
    "map_transaction['States']=map_transaction['States'].str.replace('Andaman & Nicobar Islands','Andaman & Nicobar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_user\n",
    "path6 = \"C:/Sudhakar/Projects/Phonepe Pulse Data/Dataset & Documents/pulse/data/map/user/hover/country/india/state/\"\n",
    "Column6 = {\"States\":[], \"Years\":[], \"Quarters\":[], \"District\":[], \"RegisteredUsers_count\":[], \"AppOpens_count\":[]}\n",
    "\n",
    "map_user_state_list = os.listdir(path6)\n",
    "for state in map_user_state_list:\n",
    "    current_state = path6 + state + \"/\"\n",
    "    #print(current_state)\n",
    "    \n",
    "    map_user_year_list = os.listdir(current_state)\n",
    "    for year in map_user_year_list:\n",
    "        current_year = current_state + year + \"/\"\n",
    "        #print(current_year)\n",
    "        \n",
    "        map_user_file_list = os.listdir(current_year)\n",
    "        for json_file in map_user_file_list:\n",
    "            current_json_file = current_year + json_file\n",
    "            #print(current_json_file)\n",
    "            \n",
    "            map_user_json_file_data = open(current_json_file, \"r\")\n",
    "            map_user_json_File_values = json.load(map_user_json_file_data)\n",
    "            #print(map_user_json_File_values)\n",
    "            \n",
    "            for map_user_json_File_values_get in map_user_json_File_values[\"data\"][\"hoverData\"].items():\n",
    "                District = map_user_json_File_values_get[0]\n",
    "                Reg_User = map_user_json_File_values_get[1][\"registeredUsers\"]\n",
    "                App_opens = map_user_json_File_values_get[1][\"appOpens\"]\n",
    "                \n",
    "                Column6[\"States\"].append(state)\n",
    "                Column6[\"Years\"].append(year)\n",
    "                Column6[\"Quarters\"].append(int(json_file.strip(\".json\")))\n",
    "                Column6[\"District\"].append(District)\n",
    "                Column6[\"RegisteredUsers_count\"].append(Reg_User)\n",
    "                Column6[\"AppOpens_count\"].append(App_opens)\n",
    "                \n",
    "map_user = pd.DataFrame(Column6)\n",
    "\n",
    "map_user['States']=map_user['States'].str.title()\n",
    "map_user['States']=map_user['States'].str.replace('-',' ')\n",
    "map_user['States']=map_user['States'].str.replace('Dadra & Nagar Haveli & Daman & Diu' , 'Dadra and Nagar Haveli and Daman and Diu')\n",
    "map_user['States']=map_user['States'].str.replace('Andaman & Nicobar Islands','Andaman & Nicobar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_insurance\n",
    "path7 = \"C:/Sudhakar/Projects/Phonepe Pulse Data/Dataset & Documents/pulse/data/top/insurance/country/india/state/\"\n",
    "Column7 = {\"States\":[], \"Years\":[], \"Quarters\":[], \"Pincode\":[], \"Transaction_count\":[], \"Transaction_amount\":[]}\n",
    "\n",
    "top_insurance_state_list = os.listdir(path7)\n",
    "for state in top_insurance_state_list:\n",
    "    current_state = path7 + state + \"/\"\n",
    "    #print(current_state)\n",
    "    \n",
    "    top_insurance_year_list = os.listdir(current_state)\n",
    "    for year in top_insurance_year_list:\n",
    "        current_year = current_state + year + \"/\"\n",
    "        #print(current_year)\n",
    "        \n",
    "        top_insurance_json_file_list = os.listdir(current_year)\n",
    "        for json_file in top_insurance_json_file_list:\n",
    "            current_json_file = current_year + json_file\n",
    "            #print(current_json_file)\n",
    "            \n",
    "            top_insurance_json_file_data = open(current_json_file, \"r\")\n",
    "            top_insurance_json_File_values = json.load(top_insurance_json_file_data)\n",
    "            #print(top_trans_json_File_values)\n",
    "            \n",
    "            for top_insurance_json_File_values_get in top_insurance_json_File_values['data']['pincodes']:\n",
    "                entityName = top_insurance_json_File_values_get['entityName']\n",
    "                Count = top_insurance_json_File_values_get['metric']['count']\n",
    "                Amount = top_insurance_json_File_values_get['metric']['amount']\n",
    "                \n",
    "                Column7[\"States\"].append(state)\n",
    "                Column7[\"Years\"].append(year)\n",
    "                Column7[\"Quarters\"].append(int(json_file.strip(\".json\")))\n",
    "                Column7[\"Pincode\"].append(entityName)\n",
    "                Column7[\"Transaction_count\"].append(Count)\n",
    "                Column7[\"Transaction_amount\"].append(Amount)\n",
    "                \n",
    "top_insurance = pd.DataFrame(Column7)\n",
    "\n",
    "top_insurance['States']=top_insurance['States'].str.title()\n",
    "top_insurance['States']=top_insurance['States'].str.replace('-',' ')\n",
    "top_insurance['States']=top_insurance['States'].str.replace('Dadra & Nagar Haveli & Daman & Diu' , 'Dadra and Nagar Haveli and Daman and Diu')\n",
    "top_insurance['States']=top_insurance['States'].str.replace('Andaman & Nicobar Islands','Andaman & Nicobar')\n",
    "                \n",
    "                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_trans\n",
    "path8 = \"C:/Sudhakar/Projects/Phonepe Pulse Data/Dataset & Documents/pulse/data/top/transaction/country/india/state/\"\n",
    "Column8 = {\"States\":[], \"Years\":[], \"Quarters\":[], \"Pincode\":[], \"Transaction_count\":[], \"Transaction_amount\":[]}\n",
    "\n",
    "top_trans_state_list = os.listdir(path8)\n",
    "for state in top_trans_state_list:\n",
    "    current_state = path8 + state + \"/\"\n",
    "    #print(current_state)\n",
    "    \n",
    "    top_trans_year_list = os.listdir(current_state)\n",
    "    for year in top_trans_year_list:\n",
    "        current_year = current_state + year + \"/\"\n",
    "        #print(current_year)\n",
    "        \n",
    "        top_trans_json_file_list = os.listdir(current_year)\n",
    "        for json_file in top_trans_json_file_list:\n",
    "            current_json_file = current_year + json_file\n",
    "            #print(current_json_file)\n",
    "            \n",
    "            top_trans_json_file_data = open(current_json_file, \"r\")\n",
    "            top_trans_json_File_values = json.load(top_trans_json_file_data)\n",
    "            #print(top_trans_json_File_values)\n",
    "            \n",
    "            for top_trans_json_File_values_get in top_trans_json_File_values[\"data\"][\"pincodes\"]:\n",
    "                entityName = top_trans_json_File_values_get['entityName']\n",
    "                Count = top_trans_json_File_values_get['metric']['count']\n",
    "                Amount = top_trans_json_File_values_get['metric']['amount']\n",
    "                \n",
    "                Column8[\"States\"].append(state)\n",
    "                Column8[\"Years\"].append(year)\n",
    "                Column8[\"Quarters\"].append(int(json_file.strip(\".json\")))\n",
    "                Column8[\"Pincode\"].append(entityName)\n",
    "                Column8[\"Transaction_count\"].append(Count)\n",
    "                Column8[\"Transaction_amount\"].append(Amount)\n",
    "                \n",
    "top_transaction = pd. DataFrame(Column8)\n",
    "\n",
    "top_transaction['States']=top_transaction['States'].str.title()\n",
    "top_transaction['States']=top_transaction['States'].str.replace('-',' ')\n",
    "top_transaction['States']=top_transaction['States'].str.replace('Dadra & Nagar Haveli & Daman & Diu' , 'Dadra and Nagar Haveli and Daman and Diu')\n",
    "top_transaction['States']=top_transaction['States'].str.replace('Andaman & Nicobar Islands','Andaman & Nicobar')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_transaction       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_user\n",
    "path9 = \"C:/Sudhakar/Projects/Phonepe Pulse Data/Dataset & Documents/pulse/data/top/user/country/india/state/\"\n",
    "Column9 = {\"States\":[], \"Years\":[], \"Quarters\":[], \"Pincode\":[], \"RegisteredUsers\":[]}\n",
    "\n",
    "top_user_state_list = os.listdir(path9)\n",
    "for state in top_user_state_list:\n",
    "    current_state = path9 + state + \"/\"\n",
    "    #print(current_state)\n",
    "    \n",
    "    top_user_year_list = os.listdir(current_state)\n",
    "    for year in top_user_year_list:\n",
    "        current_year = current_state + year + \"/\"\n",
    "        #print(current_year)\n",
    "        \n",
    "        top_user_json_file_list = os.listdir(current_year)\n",
    "        for json_file in top_user_json_file_list:\n",
    "            current_json_file = current_year + json_file\n",
    "            #print(current_json_file)\n",
    "            \n",
    "            top_user_json_file_data = open(current_json_file, \"r\")\n",
    "            top_user_json_File_values = json.load(top_user_json_file_data)\n",
    "            #print(top_user_json_File_values)\n",
    "            \n",
    "            for top_user_json_File_values_get in top_user_json_File_values[\"data\"][\"pincodes\"]:\n",
    "                entityName = top_user_json_File_values_get['name']\n",
    "                registeredUsers = top_user_json_File_values_get['registeredUsers']\n",
    "                \n",
    "                Column9[\"States\"].append(state)\n",
    "                Column9[\"Years\"].append(year)\n",
    "                Column9[\"Quarters\"].append(int(json_file.strip(\".json\")))\n",
    "                Column9[\"Pincode\"].append(entityName)\n",
    "                Column9[\"RegisteredUsers\"].append(Count)\n",
    "                \n",
    "top_user = pd.DataFrame(Column9)\n",
    "\n",
    "top_user['States']=top_user['States'].str.title()\n",
    "top_user['States']=top_user['States'].str.replace('-',' ')\n",
    "top_user['States']=top_user['States'].str.replace('Dadra & Nagar Haveli & Daman & Diu' , 'Dadra and Nagar Haveli and Daman and Diu')\n",
    "top_user['States']=top_user['States'].str.replace('Andaman & Nicobar Islands','Andaman & Nicobar')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table Creation\n",
    "\n",
    "#SQL Connection\n",
    "postgres_connection = psycopg2.connect(host = 'localhost',\n",
    "                                       user = 'postgres',\n",
    "                                       password = 'sudhakar',\n",
    "                                       database = 'phonepe_data',\n",
    "                                       port = 5432)\n",
    "postgres_cursor = postgres_connection.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregated insurance table\n",
    "create_query_1 = '''CREATE table if not exists aggregated_insurance(States varchar(50),\n",
    "                                                                    Years int,\n",
    "                                                                    Quarters int,\n",
    "                                                                    Transaction_type varchar(200),\n",
    "                                                                    Transaction_count bigint,\n",
    "                                                                    Transaction_amount bigint)'''\n",
    "postgres_cursor.execute(create_query_1)\n",
    "postgres_connection.commit()\n",
    "\n",
    "insert_query_1 = '''INSERT into aggregated_insurance(States, Years, Quarters, Transaction_type, Transaction_count, Transaction_amount)\n",
    "                    values (%s, %s, %s,%s, %s, %s)'''\n",
    "                    \n",
    "agg_insurance_data = aggre_insurance.values.tolist()\n",
    "postgres_cursor.executemany(insert_query_1, agg_insurance_data)\n",
    "postgres_connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregated transaction table\n",
    "create_query_2 = '''CREATE table if not exists aggregated_transaction(States varchar(50),\n",
    "                                                                        Years int,\n",
    "                                                                        Quarters int,\n",
    "                                                                        Transaction_type varchar(200),\n",
    "                                                                        Transaction_count bigint,\n",
    "                                                                        Transaction_amount bigint)'''\n",
    "postgres_cursor.execute(create_query_2)\n",
    "postgres_connection.commit()\n",
    "\n",
    "insert_query_2 = '''INSERT into aggregated_transaction(States, Years, Quarters, Transaction_type, Transaction_count, Transaction_amount)\n",
    "                    values (%s, %s, %s,%s, %s, %s)'''\n",
    "                    \n",
    "agg_transaction_data = aggre_transaction.values.tolist()\n",
    "postgres_cursor.executemany(insert_query_2, agg_transaction_data)\n",
    "postgres_connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregated user table\n",
    "create_query_3 = '''CREATE table if not exists aggregated_user(States varchar(50),\n",
    "                                                                Years int,\n",
    "                                                                Quarters int,\n",
    "                                                                Brands varchar(100),\n",
    "                                                                Transaction_count bigint,\n",
    "                                                                Percentage float)'''\n",
    "postgres_cursor.execute(create_query_3)\n",
    "postgres_connection.commit()\n",
    "\n",
    "insert_query_3 = '''INSERT into aggregated_user(States, Years, Quarters, Brands, Transaction_count, Percentage)\n",
    "                    values (%s, %s, %s,%s, %s, %s)'''\n",
    "                    \n",
    "aggre_user_data = aggre_user.values.tolist()\n",
    "postgres_cursor.executemany(insert_query_3, aggre_user_data)\n",
    "postgres_connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map insurance table\n",
    "create_query_4 = '''CREATE table if not exists map_insurance(States varchar(50),\n",
    "                                                                Years int,\n",
    "                                                                Quarters int,\n",
    "                                                                District varchar(100),\n",
    "                                                                Transaction_count bigint,\n",
    "                                                                Transaction_amount bigint)'''\n",
    "postgres_cursor.execute(create_query_4)\n",
    "postgres_connection.commit()\n",
    "\n",
    "insert_query_4 = '''INSERT into map_insurance(States, Years, Quarters, District, Transaction_count, Transaction_amount)\n",
    "                    values (%s, %s, %s,%s, %s, %s)'''\n",
    "                    \n",
    "map_insurance_data = map_insurance.values.tolist()\n",
    "postgres_cursor.executemany(insert_query_4, map_insurance_data)\n",
    "postgres_connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map transaction table\n",
    "create_query_5 = '''CREATE table if not exists map_transaction (States varchar(50),\n",
    "                                                                Years int,\n",
    "                                                                Quarters int,\n",
    "                                                                District varchar(100),\n",
    "                                                                Transaction_count bigint,\n",
    "                                                                Transaction_amount bigint)'''\n",
    "postgres_cursor.execute(create_query_5)\n",
    "postgres_connection.commit()\n",
    "\n",
    "insert_query_5 = '''INSERT into map_transaction(States, Years, Quarters, District, Transaction_count, Transaction_amount)\n",
    "                    values (%s, %s, %s,%s, %s, %s)'''\n",
    "                    \n",
    "map_trans_data = map_transaction.values.tolist()\n",
    "postgres_cursor.executemany(insert_query_5, map_trans_data)\n",
    "postgres_connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map user table\n",
    "create_query_6 = '''CREATE table if not exists map_user (States varchar(50),\n",
    "                                                            Years int,\n",
    "                                                            Quarters int,\n",
    "                                                            District varchar(100),\n",
    "                                                            RegisteredUsers_count bigint,\n",
    "                                                            AppOpens_count bigint)'''\n",
    "postgres_cursor.execute(create_query_6)\n",
    "postgres_connection.commit()\n",
    "\n",
    "insert_query_6 = '''INSERT into map_user (States, Years, Quarters, District, RegisteredUsers_count, AppOpens_count)\n",
    "                    values (%s, %s, %s,%s, %s, %s)'''\n",
    "                    \n",
    "map_user_data = map_user.values.tolist()\n",
    "postgres_cursor.executemany(insert_query_6, map_user_data)\n",
    "postgres_connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map user table\n",
    "create_query_6 = '''CREATE table if not exists map_user (States varchar(50),\n",
    "                                                            Years int,\n",
    "                                                            Quarters int,\n",
    "                                                            District varchar(100),\n",
    "                                                            RegisteredUsers_count bigint,\n",
    "                                                            AppOpens_count bigint)'''\n",
    "postgres_cursor.execute(create_query_6)\n",
    "postgres_connection.commit()\n",
    "\n",
    "insert_query_6 = '''INSERT into map_user (States, Years, Quarters, District, RegisteredUsers_count, AppOpens_count)\n",
    "                    values (%s, %s, %s,%s, %s, %s)'''\n",
    "                    \n",
    "map_user_data = map_user.values.tolist()\n",
    "postgres_cursor.executemany(insert_query_6, map_user_data)\n",
    "postgres_connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map user table\n",
    "create_query_6 = '''CREATE table if not exists map_user (States varchar(50),\n",
    "                                                            Years int,\n",
    "                                                            Quarters int,\n",
    "                                                            District varchar(100),\n",
    "                                                            RegisteredUsers_count bigint,\n",
    "                                                            AppOpens_count bigint)'''\n",
    "postgres_cursor.execute(create_query_6)\n",
    "postgres_connection.commit()\n",
    "\n",
    "insert_query_6 = '''INSERT into map_user (States, Years, Quarters, District, RegisteredUsers_count, AppOpens_count)\n",
    "                    values (%s, %s, %s,%s, %s, %s)'''\n",
    "                    \n",
    "map_user_data = map_user.values.tolist()\n",
    "postgres_cursor.executemany(insert_query_6, map_user_data)\n",
    "postgres_connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top insurance table\n",
    "create_query_7 = '''CREATE table if not exists top_insurance (States varchar(50),\n",
    "                                                                Years int,\n",
    "                                                                Quarters int,\n",
    "                                                                Pincode bigint,\n",
    "                                                                Transaction_count bigint,\n",
    "                                                                Transaction_amount bigint)'''\n",
    "postgres_cursor.execute(create_query_7)\n",
    "postgres_connection.commit()\n",
    "\n",
    "insert_query_7 = '''INSERT into top_insurance (States, Years, Quarters, Pincode, Transaction_count, Transaction_amount)\n",
    "                    values (%s, %s, %s,%s, %s, %s)'''\n",
    "                    \n",
    "top_insurance_data = top_insurance.values.tolist()\n",
    "postgres_cursor.executemany(insert_query_7, top_insurance_data)\n",
    "postgres_connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top transaction table\n",
    "create_query_8 = '''CREATE table if not exists top_transaction (States varchar(50),\n",
    "                                                                Years int,\n",
    "                                                                Quarters int,\n",
    "                                                                Pincode bigint,\n",
    "                                                                Transaction_count bigint,\n",
    "                                                                Transaction_amount bigint)'''\n",
    "postgres_cursor.execute(create_query_8)\n",
    "postgres_connection.commit()\n",
    "\n",
    "insert_query_8 = '''INSERT into top_transaction (States, Years, Quarters, Pincode, Transaction_count, Transaction_amount)\n",
    "                    values (%s, %s, %s,%s, %s, %s)'''\n",
    "                    \n",
    "top_trans_data = top_transaction.values.tolist()\n",
    "postgres_cursor.executemany(insert_query_8, top_trans_data)\n",
    "postgres_connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top user table\n",
    "create_query_9 = '''CREATE table if not exists top_user (States varchar(50),\n",
    "                                                            Years int,\n",
    "                                                            Quarters int,\n",
    "                                                            Pincode bigint,\n",
    "                                                            RegisteredUsers bigint)'''\n",
    "postgres_cursor.execute(create_query_9)\n",
    "postgres_connection.commit()\n",
    "\n",
    "insert_query_9 = '''INSERT into top_user (States, Years, Quarters, Pincode, RegisteredUsers)\n",
    "                    values (%s, %s, %s,%s, %s)'''\n",
    "                    \n",
    "top_user_data = top_user.values.tolist()\n",
    "postgres_cursor.executemany(insert_query_9, top_user_data)\n",
    "postgres_connection.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
